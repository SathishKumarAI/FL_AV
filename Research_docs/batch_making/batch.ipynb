{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Sets up logging configuration.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        filename=\"batch_processing.log\",\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "\n",
    "def copy_file(src, dst):\n",
    "    \"\"\"Copies a file from source to destination, logs errors if encountered.\"\"\"\n",
    "    try:\n",
    "        shutil.copy2(src, dst)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error copying {src} to {dst}: {e}\")\n",
    "\n",
    "def create_federated_batches(source_base_folder, destination_base_folder, num_batches):\n",
    "    \"\"\"Creates federated learning batches from the given dataset.\"\"\"\n",
    "    try:\n",
    "        # Define dataset mapping with correct label directories\n",
    "        dataset_mapping = {\"train\": \"det_train\", \"val\": \"det_val\", \"test\": None}  # Test has no labels\n",
    "        \n",
    "        for dataset, label_subdir in dataset_mapping.items():\n",
    "            image_source = os.path.join(source_base_folder, \"images\", dataset)\n",
    "            label_source = os.path.join(source_base_folder, \"labels\", label_subdir) if label_subdir else None\n",
    "            \n",
    "            # Ensure image directory exists, skip test labels since they do not exist\n",
    "            if not os.path.exists(image_source):\n",
    "                logging.warning(f\"Skipping {dataset} - Missing image folder: {image_source}\")\n",
    "                continue\n",
    "            \n",
    "            image_files = {os.path.splitext(f)[0]: f for f in os.listdir(image_source)}\n",
    "            label_files = {os.path.splitext(f)[0]: f for f in os.listdir(label_source)} if label_source and os.path.exists(label_source) else {}\n",
    "            \n",
    "            # If test dataset, only use images\n",
    "            matched_keys = sorted(image_files.keys() & label_files.keys()) if label_files else sorted(image_files.keys())\n",
    "            \n",
    "            if len(matched_keys) == 0:\n",
    "                logging.error(f\"No matching images and labels found in {dataset}, skipping.\")\n",
    "                continue\n",
    "            \n",
    "            total_files = len(matched_keys)\n",
    "            batch_size = max(1, total_files // num_batches)  # Ensure at least one file per batch\n",
    "            leftover = total_files % num_batches\n",
    "            \n",
    "            logging.info(f\"{dataset}: {total_files} files, Batch size: {batch_size}, Leftover: {leftover}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            index = 0\n",
    "            \n",
    "            with ThreadPoolExecutor(max_workers=8) as executor:  # Limit threads to prevent overload\n",
    "                for i in range(num_batches):\n",
    "                    batch_folder = os.path.join(destination_base_folder, f\"batch_{i+1}\", dataset)\n",
    "                    batch_image_folder = os.path.join(batch_folder, \"images\")\n",
    "                    batch_label_folder = os.path.join(batch_folder, \"labels\") if label_files else None\n",
    "                    os.makedirs(batch_image_folder, exist_ok=True)\n",
    "                    if batch_label_folder:\n",
    "                        os.makedirs(batch_label_folder, exist_ok=True)\n",
    "                    \n",
    "                    current_batch_size = batch_size + (1 if i < leftover else 0)\n",
    "                    batch_keys = matched_keys[index:index + current_batch_size]\n",
    "                    index += current_batch_size\n",
    "                    \n",
    "                    for key in batch_keys:\n",
    "                        img_src = os.path.join(image_source, image_files[key])\n",
    "                        img_dst = os.path.join(batch_image_folder, image_files[key])\n",
    "                        executor.submit(copy_file, img_src, img_dst)\n",
    "                        \n",
    "                        if label_files:\n",
    "                            lbl_src = os.path.join(label_source, label_files[key])\n",
    "                            lbl_dst = os.path.join(batch_label_folder, label_files[key])\n",
    "                            executor.submit(copy_file, lbl_src, lbl_dst)\n",
    "                    \n",
    "                    logging.info(f\"Batch {i+1} - {dataset}: {len(batch_keys)} files.\")\n",
    "            \n",
    "            end_time = time.time()\n",
    "            logging.info(f\"{dataset} batch processing completed in {end_time - start_time:.2f} seconds.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error creating batches: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup_logging()\n",
    "    source_base_folder = r\"C:\\\\Users\\\\sathish\\\\Downloads\\\\FL_ModelForAV\\\\data\\\\bdd100k\"\n",
    "    destination_base_folder = r\"C:\\\\Users\\\\sathish\\\\Downloads\\\\FL_ModelForAV\\\\data\\\\bdd100_batch\"\n",
    "    num_batches = 20\n",
    "    \n",
    "    logging.info(\"Federated batch processing started.\")\n",
    "    create_federated_batches(source_base_folder, destination_base_folder, num_batches)\n",
    "    logging.info(\"Federated batch processing completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
