{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1+cpu\n",
      "False\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Wed_Oct_30_01:18:48_Pacific_Daylight_Time_2024\n",
      "Cuda compilation tools, release 12.6, V12.6.85\n",
      "Build cuda_12.6.r12.6/compiler.35059454_0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "!nvcc -V"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##install packages\n",
    "!pip install GPUtil pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GPUtil in c:\\users\\siu856522160\\.conda\\envs\\venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: pynvml in c:\\users\\siu856522160\\.conda\\envs\\venv\\lib\\site-packages (11.5.0)\n"
     ]
    }
   ],
   "source": [
    "##install packages\n",
    "!pip install GPUtil pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CommandNotFoundError: No command 'conda pip'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda pip install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.0.1 (NVIDIA GeForce RTX 2060 SUPER)\n",
      "__CUDNN VERSION: 8500\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 2060 SUPER\n",
      "__CUDA Device Total Memory [GB]: 8.589606912\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "import GPUtil\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "GPUtil.getAvailable()\n",
    "torch.cuda.is_available()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# def report_gpu():\n",
    "#    print(torch.cuda.list_gpu_processes())\n",
    "#    gc.collect()\n",
    "#    torch.cuda.empty_cache()\n",
    "# report_gpu()\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
    "\n",
    "\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 2.0.1 (NVIDIA GeForce RTX 2060 SUPER)\n",
      "__CUDNN VERSION: 8500\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 2060 SUPER\n",
      "__CUDA Device Total Memory [GB]: 8.589606912\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "import GPUtil\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "GPUtil.getAvailable()\n",
    "torch.cuda.is_available()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# def report_gpu():\n",
    "#    print(torch.cuda.list_gpu_processes())\n",
    "#    gc.collect()\n",
    "#    torch.cuda.empty_cache()\n",
    "# report_gpu()\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print(\n",
    "    f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
    "\n",
    "\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__CUDA Device Name:', torch.cuda.get_device_name(0))\n",
    "print('__CUDA Device Total Memory [GB]:', torch.cuda.get_device_properties(\n",
    "    0).total_memory/1e9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  6 16:19:14 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.23                 Driver Version: 536.23       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2060 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 33%   33C    P8              10W / 175W |    959MiB /  8192MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      6664    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12788    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     14508    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14688    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19160    C+G   ...on\\114.0.1823.58\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     34092    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 120 --img-size 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 10 --img-size 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 120 --img-size 1024 --device 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 120 --img-size 1024 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!wandb login 47afa783acc34077ddd564575ef37be72db9ffe9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --batch 16 --data dataset.yaml --weights yolov5s.pt  --epochs 2 --img-size 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File names with './train/' saved to train.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Specify the directory path containing JPEG files\n",
    "directory_path = \"/path/to/your/directory\"\n",
    "\n",
    "# Specify the name of the output text file\n",
    "output_file = \"file_names.txt\"\n",
    "\n",
    "# Use glob to get a list of all JPEG files in the directory\n",
    "jpeg_files = glob.glob(os.path.join(directory_path, \"*.jpg\"))\n",
    "\n",
    "# Create and write the file names with relative paths to the text file\n",
    "with open(output_file, \"w\") as file:\n",
    "    for jpeg_file in jpeg_files:\n",
    "        file_name = os.path.basename(jpeg_file)\n",
    "        relative_path = os.path.join(\"./train\", file_name)  # Include \"./train/\" prefix\n",
    "        file.write(relative_path + \"\\n\")\n",
    "\n",
    "# Print a message indicating completion\n",
    "print(f\"File names with './train/' saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
